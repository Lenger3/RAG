# Code RAG ğŸ”

GitHub repository'lerini klonlayÄ±p analiz eden, ChromaDB'de indexleyen ve doÄŸal dil sorgularÄ± ile kod aramasÄ± yapabilen RAG sistemi.

## Kurulum

```bash
# 1. Virtual environment oluÅŸtur
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# 2. BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements.txt

# 3. .env dosyasÄ±nÄ± oluÅŸtur
cp .env.example .env
# .env dosyasÄ±nÄ± aÃ§Ä±p OPENAI_API_KEY'i girin
```

## KullanÄ±m

### Repo Ä°ndeksleme

```bash
python -m src.cli.main index --url https://github.com/pallets/click
```

SeÃ§enekler:
- `--url, -u` GitHub repo URL'si (zorunlu)
- `--collection, -c` Koleksiyon adÄ± (varsayÄ±lan: repo adÄ±)
- `--strategy, -s` Chunking stratejisi: `function` | `class` | `file` | `sliding` (varsayÄ±lan: `function`)
- `--max-chunk` Maksimum chunk token boyutu (varsayÄ±lan: 1000)
- `--embedding` Embedding saÄŸlayÄ±cÄ±: `local` | `openai` (varsayÄ±lan: `local`)

### Sorgulama

```bash
python -m src.cli.main query --collection click "How is command group implemented?"
```

SeÃ§enekler:
- `--collection, -c` Koleksiyon adÄ± (zorunlu)
- `--top-k, -k` KaÃ§ chunk getirileceÄŸi (varsayÄ±lan: 5)
- `--no-llm` Sadece retrieve sonuÃ§larÄ±nÄ± gÃ¶ster (LLM olmadan)
- `--stream` Streaming modda cevap al
- `--embedding` Embedding saÄŸlayÄ±cÄ±

### KoleksiyonlarÄ± Listele

```bash
python -m src.cli.main list
```

### Koleksiyon Sil

```bash
python -m src.cli.main delete --collection click
```

## Testler

```bash
pytest tests/ -v
```

## Proje YapÄ±sÄ±

```
code-rag/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ indexer/
â”‚   â”‚   â”œâ”€â”€ repo_cloner.py     # GitHub repo clone
â”‚   â”‚   â”œâ”€â”€ file_parser.py     # Dosya okuma + AST parsing
â”‚   â”‚   â”œâ”€â”€ code_chunker.py    # AkÄ±llÄ± kod chunking
â”‚   â”‚   â””â”€â”€ embedder.py        # Embedding oluÅŸturma
â”‚   â”œâ”€â”€ retriever/
â”‚   â”‚   â”œâ”€â”€ vector_store.py    # ChromaDB wrapper
â”‚   â”‚   â””â”€â”€ query_engine.py    # Sorgulama + context building
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ generator.py       # OpenAI GPT yanÄ±t Ã¼retici
â”‚   â””â”€â”€ cli/
â”‚       â””â”€â”€ main.py            # CLI interface
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ repos/                 # Clone edilen repo'lar
â”‚   â””â”€â”€ chroma_db/             # ChromaDB veritabanÄ±
â”œâ”€â”€ config/config.yaml         # Ayarlar
â”œâ”€â”€ tests/                     # Unit testler
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env.example
```

## KonfigÃ¼rasyon

`config/config.yaml` dosyasÄ±ndan tÃ¼m ayarlar yÃ¶netilebilir:

- **embedding.model**: KullanÄ±lacak sentence-transformers modeli
- **chunking.strategy**: VarsayÄ±lan chunking stratejisi
- **retrieval.top_k**: VarsayÄ±lan retrieve edilen chunk sayÄ±sÄ±
- **llm.model**: OpenAI model adÄ± (gpt-4o-mini, gpt-4, vb.)
- **chromadb.persist_directory**: ChromaDB depolama dizini

## Ã–rnek Sorgular

```bash
# Kimlik doÄŸrulama nasÄ±l implemente edilmiÅŸ?
python -m src.cli.main query -c myrepo "How is authentication implemented?"

# Hangi external kÃ¼tÃ¼phaneler kullanÄ±lÄ±yor?
python -m src.cli.main query -c myrepo "What external libraries are used for HTTP requests?"

# VeritabanÄ± baÄŸlantÄ±sÄ± nerede yapÄ±lÄ±yor?
python -m src.cli.main query -c myrepo "Where is the database connection configured?"
```
