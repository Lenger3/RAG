# Code RAG ğŸ”

GitHub repository'lerini klonlayÄ±p analiz eden, ChromaDB'de indexleyen ve **tamamen yerel** olarak doÄŸal dil sorgularÄ± ile kod aramasÄ± yapabilen RAG sistemi.

> ğŸ  **Tamamen offline Ã§alÄ±ÅŸÄ±r** â€” API key gerekmez, veriler buluta gitmez.

## Kurulum

```bash
# 1. Virtual environment oluÅŸtur
python -m venv venv
source venv/bin/activate  # Linux/Mac

# 2. BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements.txt
```

## Ollama Kurulumu (Yerel LLM)

```bash
# 1. Ollama'yÄ± yÃ¼kle â†’ https://ollama.com/download (macOS: .dmg indir ve aÃ§)

# 2. TÃ¼rkÃ§e desteÄŸi gÃ¼Ã§lÃ¼, hafif bir model Ã§ek
ollama pull qwen2.5:3b     # ~2GB â€” Ã¶nerilen
# veya
ollama pull qwen2.5:7b     # ~4.7GB â€” daha iyi kalite
```

KullanÄ±labilir modeller:

| Model | Boyut | TÃ¼rkÃ§e | HÄ±z |
|---|---|---|---|
| `qwen2.5:3b` â­ | ~2 GB | MÃ¼kemmel | Ã‡ok hÄ±zlÄ± |
| `qwen2.5:7b` | ~4.7 GB | Ã‡ok iyi | HÄ±zlÄ± |
| `llama3.2:3b` | ~2 GB | Orta | Ã‡ok hÄ±zlÄ± |
| `gemma3:4b` | ~3.3 GB | Ä°yi | HÄ±zlÄ± |

Modeli deÄŸiÅŸtirmek iÃ§in `config/config.yaml` dosyasÄ±ndan:
```yaml
llm:
  model: "qwen2.5:7b"
```

---

## KullanÄ±m

### Repo Ä°ndeksleme

```bash
python -m src.cli.main index --url https://github.com/kullanici/repo
```

SeÃ§enekler:
- `--url, -u` GitHub repo URL'si (zorunlu)
- `--collection, -c` Koleksiyon adÄ± (varsayÄ±lan: repo adÄ±)
- `--strategy, -s` Chunking stratejisi: `function` | `class` | `file` | `sliding`
- `--max-chunk` Maksimum chunk token boyutu (varsayÄ±lan: 1000)

### Sorgulama

```bash
# LLM ile cevap al
python -m src.cli.main query --collection myrepo "hangi model kullanÄ±lmÄ±ÅŸ?"

# Sadece kod parÃ§alarÄ±nÄ± getir (LLM olmadan)
python -m src.cli.main query --collection myrepo "authentication" --no-llm

# Streaming modda cevap
python -m src.cli.main query --collection myrepo "ana giriÅŸ noktasÄ± nerede?" --stream
```

SeÃ§enekler:
- `--collection, -c` Koleksiyon adÄ± (zorunlu)
- `--top-k, -k` KaÃ§ chunk getirileceÄŸi (varsayÄ±lan: 5)
- `--no-llm` Sadece retrieve sonuÃ§larÄ±nÄ± gÃ¶ster
- `--stream` Streaming modda cevap al

### KoleksiyonlarÄ± Listele

```bash
python -m src.cli.main list
```

### Koleksiyon Sil

```bash
python -m src.cli.main delete --collection myrepo
```

---

## Proje YapÄ±sÄ±

```
RAG/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ indexer/
â”‚   â”‚   â”œâ”€â”€ repo_cloner.py     # GitHub repo clone + dosya listeleme
â”‚   â”‚   â”œâ”€â”€ file_parser.py     # Dosya okuma + Python AST parsing
â”‚   â”‚   â”œâ”€â”€ code_chunker.py    # function / class / sliding chunking
â”‚   â”‚   â””â”€â”€ embedder.py        # sentence-transformers embedding (local)
â”‚   â”œâ”€â”€ retriever/
â”‚   â”‚   â”œâ”€â”€ vector_store.py    # ChromaDB wrapper
â”‚   â”‚   â””â”€â”€ query_engine.py    # Semantic search + context builder
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ generator.py       # Ollama LLM entegrasyonu
â”‚   â””â”€â”€ cli/
â”‚       â””â”€â”€ main.py            # CLI (index / query / list / delete)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ repos/                 # Clone edilen repo'lar
â”‚   â””â”€â”€ chroma_db/             # ChromaDB vektÃ¶r veritabanÄ±
â”œâ”€â”€ config/config.yaml         # TÃ¼m ayarlar
â”œâ”€â”€ tests/                     # Unit testler (32 test)
â””â”€â”€ requirements.txt
```

## KonfigÃ¼rasyon (`config/config.yaml`)

```yaml
llm:
  model: "qwen2.5:3b"           # Ollama model adÄ±
  ollama_host: "http://localhost:11434"
  temperature: 0.1
  max_tokens: 2000

retrieval:
  top_k: 5
  similarity_threshold: 0.3     # DÃ¼ÅŸÃ¼rtmek â†’ daha fazla sonuÃ§

chunking:
  strategy: "function"          # function | class | file | sliding
  max_chunk_size: 1000

embedding:
  model: "sentence-transformers/all-MiniLM-L6-v2"
  device: "cpu"                 # Apple Silicon: "mps", GPU: "cuda"
```

## Testler

```bash
pytest tests/ -v
```

## Ã–rnek Sorgular

```bash
# Hangi YOLO versiyonu kullanÄ±lmÄ±ÅŸ?
python -m src.cli.main query -c myrepo "yolo modeli olarak ne kullanÄ±lmÄ±ÅŸ"

# Authentication nasÄ±l yapÄ±lmÄ±ÅŸ?
python -m src.cli.main query -c myrepo "authentication nasÄ±l implemente edilmiÅŸ?"

# VeritabanÄ± baÄŸlantÄ±sÄ± nerede?
python -m src.cli.main query -c myrepo "veritabanÄ± baÄŸlantÄ±sÄ± nerede?"

# Hangi dÄ±ÅŸ kÃ¼tÃ¼phaneler kullanÄ±lÄ±yor?
python -m src.cli.main query -c myrepo "kullanÄ±lan kÃ¼tÃ¼phaneler neler?"
```
